#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ·±å…¥åˆ†æNPYæ–‡ä»¶å†…å®¹

@author: åˆ†æè„šæœ¬
@date: 2025-06-14
"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os

def analyze_frontalization_model(file_path):
    """æ·±å…¥åˆ†æfrontalizationæ¨¡å‹"""
    print("ğŸ”¬ æ·±å…¥åˆ†æ model_frontalization.npy")
    print("=" * 60)
    
    try:
        data = np.load(file_path)
        
        print("ğŸ“Š åŸºæœ¬ä¿¡æ¯:")
        print(f"  å½¢çŠ¶: {data.shape}")
        print(f"  æ•°æ®ç±»å‹: {data.dtype}")
        print(f"  å†…å­˜å¤§å°: {data.nbytes / 1024:.2f} KB")
        
        print("\nğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
        print(f"  æœ€å°å€¼: {np.min(data):.6f}")
        print(f"  æœ€å¤§å€¼: {np.max(data):.6f}")
        print(f"  å¹³å‡å€¼: {np.mean(data):.6f}")
        print(f"  ä¸­ä½æ•°: {np.median(data):.6f}")
        print(f"  æ ‡å‡†å·®: {np.std(data):.6f}")
        print(f"  æ–¹å·®: {np.var(data):.6f}")
        
        # åˆ†ææ¯è¡Œçš„ç»Ÿè®¡ä¿¡æ¯
        print("\nğŸ“Š æ¯è¡Œç»Ÿè®¡ä¿¡æ¯:")
        row_means = np.mean(data, axis=1)
        row_stds = np.std(data, axis=1)
        
        print(f"  è¡Œå‡å€¼èŒƒå›´: [{np.min(row_means):.6f}, {np.max(row_means):.6f}]")
        print(f"  è¡Œæ ‡å‡†å·®èŒƒå›´: [{np.min(row_stds):.6f}, {np.max(row_stds):.6f}]")
        
        # åˆ†ææ¯åˆ—çš„ç»Ÿè®¡ä¿¡æ¯
        print("\nğŸ“Š æ¯åˆ—ç»Ÿè®¡ä¿¡æ¯:")
        col_means = np.mean(data, axis=0)
        col_stds = np.std(data, axis=0)
        
        print(f"  åˆ—å‡å€¼èŒƒå›´: [{np.min(col_means):.6f}, {np.max(col_means):.6f}]")
        print(f"  åˆ—æ ‡å‡†å·®èŒƒå›´: [{np.min(col_stds):.6f}, {np.max(col_stds):.6f}]")
        
        # æŸ¥æ‰¾é›¶å€¼å’Œå¼‚å¸¸å€¼
        print("\nğŸ” æ•°æ®è´¨é‡åˆ†æ:")
        zero_count = np.sum(data == 0)
        nan_count = np.sum(np.isnan(data))
        inf_count = np.sum(np.isinf(data))
        
        print(f"  é›¶å€¼æ•°é‡: {zero_count} ({zero_count/data.size*100:.2f}%)")
        print(f"  NaNæ•°é‡: {nan_count}")
        print(f"  æ— ç©·å€¼æ•°é‡: {inf_count}")
        
        # åˆ†ææ•°æ®åˆ†å¸ƒ
        print("\nğŸ“Š æ•°æ®åˆ†å¸ƒåˆ†æ:")
        percentiles = [1, 5, 10, 25, 50, 75, 90, 95, 99]
        values = np.percentile(data, percentiles)
        
        for p, v in zip(percentiles, values):
            print(f"  ç¬¬{p}ç™¾åˆ†ä½æ•°: {v:.6f}")
        
        # æ˜¾ç¤ºæ•°æ®çš„ä¸€äº›æ ·æœ¬
        print("\nğŸ”¬ æ•°æ®æ ·æœ¬:")
        print("å‰3è¡Œå‰5åˆ—:")
        print(data[:3, :5])
        
        print("\næœ€å3è¡Œæœ€å5åˆ—:")
        print(data[-3:, -5:])
        
        # åˆ›å»ºå¯è§†åŒ–
        create_visualizations(data)
        
        return True
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def create_visualizations(data):
    """åˆ›å»ºæ•°æ®å¯è§†åŒ–"""
    print("\nğŸ“Š åˆ›å»ºå¯è§†åŒ–å›¾è¡¨...")
    
    try:
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        # åˆ›å»ºå›¾å½¢
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('Frontalizationæ¨¡å‹æ•°æ®åˆ†æ', fontsize=16)
        
        # 1. çƒ­åŠ›å›¾ (é‡‡æ ·æ˜¾ç¤ºï¼Œå› ä¸ºæ•°æ®å¤ªå¤§)
        sample_data = data[::5, ::5]  # æ¯5ä¸ªå–ä¸€ä¸ªç‚¹
        im1 = axes[0, 0].imshow(sample_data, cmap='viridis', aspect='auto')
        axes[0, 0].set_title('æ•°æ®çƒ­åŠ›å›¾ (é‡‡æ ·)')
        axes[0, 0].set_xlabel('åˆ—ç´¢å¼•')
        axes[0, 0].set_ylabel('è¡Œç´¢å¼•')
        plt.colorbar(im1, ax=axes[0, 0])
        
        # 2. æ•°æ®åˆ†å¸ƒç›´æ–¹å›¾
        axes[0, 1].hist(data.flatten(), bins=50, alpha=0.7, edgecolor='black')
        axes[0, 1].set_title('æ•°æ®å€¼åˆ†å¸ƒ')
        axes[0, 1].set_xlabel('æ•°å€¼')
        axes[0, 1].set_ylabel('é¢‘æ¬¡')
        axes[0, 1].grid(True, alpha=0.3)
        
        # 3. æ¯è¡Œçš„å‡å€¼
        row_means = np.mean(data, axis=1)
        axes[1, 0].plot(row_means, 'b-', linewidth=1)
        axes[1, 0].set_title('æ¯è¡Œå‡å€¼')
        axes[1, 0].set_xlabel('è¡Œç´¢å¼•')
        axes[1, 0].set_ylabel('å‡å€¼')
        axes[1, 0].grid(True, alpha=0.3)
        
        # 4. æ¯åˆ—çš„å‡å€¼
        col_means = np.mean(data, axis=0)
        axes[1, 1].plot(col_means, 'r-', linewidth=1)
        axes[1, 1].set_title('æ¯åˆ—å‡å€¼')
        axes[1, 1].set_xlabel('åˆ—ç´¢å¼•')
        axes[1, 1].set_ylabel('å‡å€¼')
        axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾è¡¨
        output_path = "frontalization_analysis.png"
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        print(f"  âœ… å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜åˆ°: {output_path}")
        
        # æ˜¾ç¤ºå›¾è¡¨
        plt.show()
        
    except Exception as e:
        print(f"  âŒ å¯è§†åŒ–åˆ›å»ºå¤±è´¥: {str(e)}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”¬ NPYæ–‡ä»¶æ·±åº¦åˆ†æå™¨")
    print("=" * 60)
    
    npy_file_path = "D:\\pythonpro\\facial-expression-analysis-main\\models\\model_frontalization.npy"
    
    if os.path.exists(npy_file_path):
        analyze_frontalization_model(npy_file_path)
    else:
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {npy_file_path}")
    
    print("\n" + "=" * 60)
    print("ğŸ‰ åˆ†æå®Œæˆ")

if __name__ == "__main__":
    main()

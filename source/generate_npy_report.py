#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
NPYæ–‡ä»¶åˆ†ææŠ¥å‘Šç”Ÿæˆå™¨

@author: æŠ¥å‘Šç”Ÿæˆå™¨
@date: 2025-06-14
"""

import numpy as np
import os
from datetime import datetime

def generate_npy_report(file_path):
    """ç”ŸæˆNPYæ–‡ä»¶åˆ†ææŠ¥å‘Š"""
    
    report = []
    report.append("=" * 80)
    report.append("NPYæ–‡ä»¶åˆ†ææŠ¥å‘Š")
    report.append("=" * 80)
    report.append(f"æ–‡ä»¶è·¯å¾„: {file_path}")
    report.append(f"åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report.append("")
    
    try:
        # è¯»å–æ•°æ®
        data = np.load(file_path)
        file_size = os.path.getsize(file_path)
        
        # åŸºæœ¬ä¿¡æ¯
        report.append("ğŸ“Š åŸºæœ¬ä¿¡æ¯")
        report.append("-" * 40)
        report.append(f"æ–‡ä»¶å¤§å°: {file_size:,} bytes ({file_size/1024:.2f} KB)")
        report.append(f"æ•°æ®ç±»å‹: {type(data).__name__}")
        report.append(f"æ•°æ®å½¢çŠ¶: {data.shape}")
        report.append(f"æ•°æ®ç±»å‹: {data.dtype}")
        report.append(f"å…ƒç´ æ€»æ•°: {data.size:,}")
        report.append(f"ç»´åº¦æ•°: {data.ndim}")
        report.append(f"å†…å­˜å ç”¨: {data.nbytes:,} bytes ({data.nbytes/1024:.2f} KB)")
        report.append("")
        
        # ç»Ÿè®¡ä¿¡æ¯
        report.append("ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯")
        report.append("-" * 40)
        report.append(f"æ•°å€¼èŒƒå›´: [{np.min(data):.6f}, {np.max(data):.6f}]")
        report.append(f"å¹³å‡å€¼: {np.mean(data):.6f}")
        report.append(f"ä¸­ä½æ•°: {np.median(data):.6f}")
        report.append(f"æ ‡å‡†å·®: {np.std(data):.6f}")
        report.append(f"æ–¹å·®: {np.var(data):.6f}")
        report.append("")
        
        # ç™¾åˆ†ä½æ•°
        report.append("ğŸ“Š æ•°æ®åˆ†å¸ƒ (ç™¾åˆ†ä½æ•°)")
        report.append("-" * 40)
        percentiles = [1, 5, 10, 25, 50, 75, 90, 95, 99]
        values = np.percentile(data, percentiles)
        for p, v in zip(percentiles, values):
            report.append(f"ç¬¬{p:2d}ç™¾åˆ†ä½æ•°: {v:10.6f}")
        report.append("")
        
        # æ•°æ®è´¨é‡
        report.append("ğŸ” æ•°æ®è´¨é‡")
        report.append("-" * 40)
        zero_count = np.sum(data == 0)
        nan_count = np.sum(np.isnan(data))
        inf_count = np.sum(np.isinf(data))
        
        report.append(f"é›¶å€¼æ•°é‡: {zero_count:,} ({zero_count/data.size*100:.2f}%)")
        report.append(f"NaNæ•°é‡: {nan_count:,}")
        report.append(f"æ— ç©·å€¼æ•°é‡: {inf_count:,}")
        report.append("")
        
        # æŒ‰è¡Œ/åˆ—åˆ†æ
        if data.ndim == 2:
            report.append("ğŸ“Š çŸ©é˜µåˆ†æ")
            report.append("-" * 40)
            
            # è¡Œç»Ÿè®¡
            row_means = np.mean(data, axis=1)
            row_stds = np.std(data, axis=1)
            report.append(f"è¡Œæ•°: {data.shape[0]}")
            report.append(f"è¡Œå‡å€¼èŒƒå›´: [{np.min(row_means):.6f}, {np.max(row_means):.6f}]")
            report.append(f"è¡Œæ ‡å‡†å·®èŒƒå›´: [{np.min(row_stds):.6f}, {np.max(row_stds):.6f}]")
            
            # åˆ—ç»Ÿè®¡
            col_means = np.mean(data, axis=0)
            col_stds = np.std(data, axis=0)
            report.append(f"åˆ—æ•°: {data.shape[1]}")
            report.append(f"åˆ—å‡å€¼èŒƒå›´: [{np.min(col_means):.6f}, {np.max(col_means):.6f}]")
            report.append(f"åˆ—æ ‡å‡†å·®èŒƒå›´: [{np.min(col_stds):.6f}, {np.max(col_stds):.6f}]")
            report.append("")
        
        # æ•°æ®æ ·æœ¬
        report.append("ğŸ”¬ æ•°æ®æ ·æœ¬")
        report.append("-" * 40)
        if data.ndim == 2:
            report.append("å‰3è¡Œå‰5åˆ—:")
            sample = data[:3, :5]
            for i, row in enumerate(sample):
                report.append(f"è¡Œ{i}: " + " ".join([f"{val:8.4f}" for val in row]))
            
            report.append("\nå3è¡Œå5åˆ—:")
            sample = data[-3:, -5:]
            for i, row in enumerate(sample):
                report.append(f"è¡Œ{data.shape[0]-3+i}: " + " ".join([f"{val:8.4f}" for val in row]))
        else:
            report.append("å‰10ä¸ªå…ƒç´ :")
            report.append(str(data.flat[:10]))
        
        report.append("")
        
        # ç”¨é€”æ¨æµ‹
        report.append("ğŸ’¡ æ¨¡å‹ç”¨é€”æ¨æµ‹")
        report.append("-" * 40)
        if "frontalization" in file_path.lower():
            report.append("æ ¹æ®æ–‡ä»¶åæ¨æµ‹ï¼Œè¿™æ˜¯ä¸€ä¸ªäººè„¸æ­£é¢åŒ–æ¨¡å‹:")
            report.append("- ç”¨äºå°†ä¾§è„¸æˆ–å€¾æ–œçš„äººè„¸å›¾åƒè½¬æ¢ä¸ºæ­£é¢è§†è§’")
            report.append("- çŸ©é˜µç»´åº¦137x136å¯èƒ½å¯¹åº”ç‰¹å®šçš„ç‰¹å¾æ˜ å°„æˆ–å˜æ¢å‚æ•°")
            report.append("- æ•°å€¼èŒƒå›´åœ¨[-1, 1]ä¹‹é—´ï¼Œç¬¦åˆå½’ä¸€åŒ–çš„å˜æ¢çŸ©é˜µç‰¹å¾")
            report.append("- å¹³å‡å€¼æ¥è¿‘0è¡¨æ˜å˜æ¢æ˜¯ä¸­å¿ƒåŒ–çš„")
        
        report.append("")
        report.append("=" * 80)
        report.append("åˆ†æå®Œæˆ")
        report.append("=" * 80)
        
        return "\n".join(report)
        
    except Exception as e:
        report.append(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        return "\n".join(report)

def main():
    """ä¸»å‡½æ•°"""
    file_path = "D:\\pythonpro\\facial-expression-analysis-main\\models\\model_frontalization.npy"
    
    # ç”ŸæˆæŠ¥å‘Š
    report_content = generate_npy_report(file_path)
    
    # æ˜¾ç¤ºæŠ¥å‘Š
    print(report_content)
    
    # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
    report_file = "npy_analysis_report.txt"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report_content)
    
    print(f"\nğŸ“ å®Œæ•´æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")

if __name__ == "__main__":
    main()

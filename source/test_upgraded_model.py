#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•å‡çº§åçš„æ¨¡å‹

@author: æµ‹è¯•è„šæœ¬
@date: 2025-06-13
"""

import sys
import os
sys.path.append('../source')


import numpy as np
import cv2
import dlib
import imageio
from joblib import load
from emotions_dlib import EmotionsDlib
import math

def test_model_loading():
    """æµ‹è¯•æ¨¡å‹åŠ è½½"""
    print("æµ‹è¯•æ¨¡å‹åŠ è½½...")
    
    model_path = "D:\\pythonpro\\facial-expression-analysis-main\\models\\model_emotion_pls=30_fullfeatures=False_py312.joblib"
    
    try:
        model_data = load(model_path)
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        print(f"  - Python ç‰ˆæœ¬: {model_data.get('python_version', 'unknown')}")
        print(f"  - ç»„ä»¶æ•°: {model_data['components']}")
        print(f"  - å®Œæ•´ç‰¹å¾: {model_data['full_features']}")
        return True
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
        return False

def test_emotion_estimation():
    """æµ‹è¯•æƒ…æ„Ÿä¼°è®¡"""
    print("\næµ‹è¯•æƒ…æ„Ÿä¼°è®¡...")
    
    try:
        # è®¾ç½®æ£€æµ‹å™¨å’Œæ¨¡å‹
        detector = dlib.get_frontal_face_detector()
        predictor = dlib.shape_predictor("D:\\pythonpro\\facial-expression-analysis-main\\models\\shape_predictor_68_face_landmarks.dat")
        
        emotion_estimator = EmotionsDlib(
            file_emotion_model="D:\\pythonpro\\facial-expression-analysis-main\\models\\model_emotion_pls=30_fullfeatures=False_py312.joblib",
            file_frontalization_model="D:\\pythonpro\\facial-expression-analysis-main\\models\\model_frontalization.npy"
        )          # æµ‹è¯•å›¾åƒ
        test_images = [
            'D:\\pythonpro\\facial-expression-analysis-main\\data\\images\\pleased.jpg'
        ]
        
        for img_path in test_images:
            if os.path.exists(img_path):
                print(f"\næµ‹è¯•å›¾åƒ: {os.path.basename(img_path)}")
                
                image = cv2.imread(img_path)
                # å¦‚æœéœ€è¦RGBæ ¼å¼ï¼ˆopencvé»˜è®¤æ˜¯BGRï¼‰
                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                faces = detector(image)
                
                if len(faces) > 0:
                    face = faces[0]
                    landmarks_object = predictor(image, face)
                    
                    print("Landmarks object:", landmarks_object.parts())
                    
                    # è°ƒè¯•åŸå§‹landmarks 
                    raw_landmarks = np.array([[p.x, p.y] for p in landmarks_object.parts()])
                    print(f"Raw landmarks (numpy): {raw_landmarks[:10]}")
                    
                    # è°ƒè¯•frontalization weights
                    print(f"Frontalization weights shape: {emotion_estimator.frontalizer.frontalization_weights.shape}")
                    print(f"First few weights: {emotion_estimator.frontalizer.frontalization_weights[0, :5]}")
                    print(f"Second row weights: {emotion_estimator.frontalizer.frontalization_weights[1, :5]}")
                    
                    # è°ƒè¯•æ­£é¢åŒ–è¿‡ç¨‹
                    dict_landmarks = emotion_estimator.frontalizer.frontalize_landmarks(landmarks_object)
                    
                    # è°ƒè¯• Procrustes æ ‡å‡†åŒ–æ­¥éª¤
                    landmarks_array = np.array([[p.x, p.y] for p in landmarks_object.parts()])
                    
                    # æ­¥éª¤1ï¼šå¹³ç§»ï¼ˆä¸­å¿ƒåŒ–ï¼‰
                    landmark_mean = np.mean(landmarks_array, axis=0)
                    landmarks_centered = landmarks_array - landmark_mean
                    print(f"Mean landmark: {landmark_mean}")
                    print(f"First few centered landmarks: {landmarks_centered[:5]}")
                    
                    # æ­¥éª¤2ï¼šç¼©æ”¾
                    landmark_scale = math.sqrt(np.mean(np.sum(landmarks_centered**2, axis=1)))
                    landmarks_scaled = landmarks_centered / landmark_scale
                    print(f"Calculated scale: {landmark_scale}")
                    print(f"First few scaled landmarks: {landmarks_scaled[:5]}")
                    
                    # æ­¥éª¤3ï¼šæ—‹è½¬ï¼ˆè°ƒè¯•ï¼‰
                    # è®¡ç®—çœ¼ç›ä¸­å¿ƒ
                    center_eye_left = np.mean(landmarks_scaled[36:42], axis=0)
                    center_eye_right = np.mean(landmarks_scaled[42:48], axis=0)
                    print(f"Eye centers: left{center_eye_left}, right{center_eye_right}")
                    
                    # è®¡ç®—æ—‹è½¬è§’åº¦
                    dx = center_eye_right[0] - center_eye_left[0]
                    dy = center_eye_right[1] - center_eye_left[1]
                    print(f"Eye distance: dx={dx}, dy={dy}")
                    
                    if dx != 0:
                        angle = math.atan(dy / dx)
                        print(f"Rotation angle: {angle} radians ({math.degrees(angle)} degrees)")
                    
                    # è°ƒè¯• Procrustes æ ‡å‡†åŒ–
                    landmarks_standard = emotion_estimator.frontalizer.get_procrustes(np.array([[p.x, p.y] for p in landmarks_object.parts()]))
                    print(f"First few standardized landmarks: {landmarks_standard[:5]}")
                    
                    landmarks_frontal = dict_landmarks['landmarks_frontal']
                    landmarks_raw = dict_landmarks['landmarks_raw']
                    
                    print(f"Raw landmarks shape: {landmarks_raw.shape}")
                    print(f"Frontal landmarks shape: {landmarks_frontal.shape}")
                    print(f"First few raw landmarks: {landmarks_raw[:5]}")
                    print(f"First few frontal landmarks: {landmarks_frontal[:5]}")
                    
                    # è°ƒè¯•ç‰¹å¾æ¨¡æ¿
                    print(f"Feature template shape: {emotion_estimator.geom_feat.feature_template.shape}")
                    print(f"First 10 feature pairs: {emotion_estimator.geom_feat.feature_template[:10]}")
                      # æ‰‹åŠ¨è®¡ç®—å‰å‡ ä¸ªç‰¹å¾è¿›è¡Œæ¯”è¾ƒ
                    frontal_landmarks_17_67 = landmarks_frontal[17:68]  # landmarks 17-67
                    feature_scale = emotion_estimator.geom_feat.get_scale(landmarks_frontal)
                    
                    print(f"Manual feature calculation:")
                    for i in range(min(5, len(frontal_landmarks_17_67))):
                        for j in range(i + 1, min(i + 6, len(frontal_landmarks_17_67))):
                            if j - i <= 5:  # Only first few pairs
                                p1 = frontal_landmarks_17_67[i]
                                p2 = frontal_landmarks_17_67[j]
                                raw_dist = math.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)
                                normalized_dist = raw_dist / feature_scale
                                actual_idx1 = i + 17
                                actual_idx2 = j + 17
                                print(f"landmarks[{actual_idx1}] ({p1[0]:.6f},{p1[1]:.6f}) and landmarks[{actual_idx2}] ({p2[0]:.6f},{p2[1]:.6f}) -> raw_dist={raw_dist:.6f}, normalized={normalized_dist:.6f}")
                    
                    # è°ƒè¯•ç‰¹å¾æå–è¿‡ç¨‹
                    features = emotion_estimator.geom_feat.get_features(landmarks_frontal)
                    print(f"Features shape: {features.shape}")
                    print(f"First 10 features: {features[:10]}")
                    print(f"Feature min/max: {features.min():.6f} / {features.max():.6f}")
                    
                    # è°ƒè¯•ç‰¹å¾æå–æ—¶çš„scaleè®¡ç®—
                    feature_scale = emotion_estimator.geom_feat.get_scale(landmarks_frontal)
                    print(f"Feature extraction scale: {feature_scale:.6f}")
                    
                    # è°ƒè¯•scaleè®¡ç®—
                    scale = emotion_estimator.geom_feat.get_scale(landmarks_frontal)
                    print(f"Scale: {scale:.6f}")
                    
                    # è°ƒè¯• landmark_indx
                    print(f"Landmark indices used: start={emotion_estimator.geom_feat.landmark_indx[0]}, end={emotion_estimator.geom_feat.landmark_indx[-1]}, count={len(emotion_estimator.geom_feat.landmark_indx)}")
                    
                    # æœ€ç»ˆé¢„æµ‹
                    dict_emotions = emotion_estimator.get_emotions(landmarks_object)
                    
                    arousal = dict_emotions['emotions']['arousal']
                    valence = dict_emotions['emotions']['valence']
                    intensity = dict_emotions['emotions']['intensity']
                    emotion_name = dict_emotions['emotions']['name']
                    
                    print(f"  - Arousal: {arousal}")
                    print(f"  - Valence: {valence}")
                    print(f"  - Intensity: {intensity}")
                    print(f"  - Emotion: {emotion_name}")
                else:
                    print("  - æœªæ£€æµ‹åˆ°äººè„¸")
            else:
                print(f"  - å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {img_path}")
        
        print("âœ… æƒ…æ„Ÿä¼°è®¡æµ‹è¯•å®Œæˆ")
        return True
        
    except Exception as e:
        print(f"âŒ æƒ…æ„Ÿä¼°è®¡æµ‹è¯•å¤±è´¥: {str(e)}")
        return False

if __name__ == "__main__":
    print("=" * 50)
    print("æµ‹è¯•å‡çº§åçš„æƒ…æ„Ÿåˆ†ææ¨¡å‹")
    print("=" * 50)
    
    # æµ‹è¯•æ¨¡å‹åŠ è½½
    loading_success = test_model_loading()
    
    if loading_success:
        # æµ‹è¯•æƒ…æ„Ÿä¼°è®¡
        estimation_success = test_emotion_estimation()
        
        if estimation_success:
            print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ¨¡å‹å‡çº§æˆåŠŸã€‚")
        else:
            print("\nâš ï¸  æ¨¡å‹åŠ è½½æˆåŠŸï¼Œä½†æƒ…æ„Ÿä¼°è®¡æµ‹è¯•å¤±è´¥ã€‚")
    else:
        print("\nâŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥å‡çº§è¿‡ç¨‹ã€‚")
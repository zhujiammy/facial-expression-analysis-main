#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç”Ÿæˆç”¨äºC++ç¨‹åºæµ‹è¯•çš„Pythonå‚è€ƒç»“æœ

@author: æµ‹è¯•è„šæœ¬
@date: 2025-06-14
"""

import sys
import os
import numpy as np
import json
from pathlib import Path

# æ·»åŠ æºç è·¯å¾„
sys.path.append('../source')

try:
    from joblib import load
    from emotions_dlib import EmotionsDlib
    import cv2
    import dlib
except ImportError as e:
    print(f"å¯¼å…¥é”™è¯¯: {e}")
    print("è¯·ç¡®ä¿å®‰è£…äº†æ‰€æœ‰å¿…è¦çš„ä¾èµ–é¡¹")
    sys.exit(1)

class PythonReferenceGenerator:
    """ç”ŸæˆPythonå‚è€ƒç»“æœçš„ç±»"""
    
    def __init__(self, models_dir="../models"):
        self.models_dir = Path(models_dir)
        self.joblib_model_path = self.models_dir / "model_emotion_pls=30_fullfeatures=False_py312.joblib"
        self.frontalization_model_path = self.models_dir / "model_frontalization.npy"
        self.shape_predictor_path = self.models_dir / "shape_predictor_68_face_landmarks.dat"
        
        self.emotion_estimator = None
        self.detector = None
        self.predictor = None
        self.sklearn_model = None
        
    def load_models(self):
        """åŠ è½½æ‰€æœ‰å¿…è¦çš„æ¨¡å‹"""
        print("åŠ è½½Pythonæ¨¡å‹...")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        for path in [self.joblib_model_path, self.frontalization_model_path, self.shape_predictor_path]:
            if not path.exists():
                raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {path}")
        
        # åŠ è½½joblibæ¨¡å‹
        model_data = load(str(self.joblib_model_path))
        self.sklearn_model = model_data['model']
        
        print(f"æ¨¡å‹ç»„ä»¶æ•°: {model_data['components']}")
        print(f"å®Œæ•´ç‰¹å¾: {model_data['full_features']}")
        
        # åŠ è½½æƒ…æ„Ÿåˆ†æå™¨
        self.emotion_estimator = EmotionsDlib(
            file_emotion_model=str(self.joblib_model_path),
            file_frontalization_model=str(self.frontalization_model_path)
        )
        
        # åŠ è½½dlibæ£€æµ‹å™¨
        self.detector = dlib.get_frontal_face_detector()
        self.predictor = dlib.shape_predictor(str(self.shape_predictor_path))
        
        print("âœ… æ‰€æœ‰æ¨¡å‹åŠ è½½æˆåŠŸ")
        
    def analyze_image(self, image_path):
        """åˆ†æå•å¼ å›¾åƒ"""
        print(f"åˆ†æå›¾åƒ: {image_path}")
        
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
        
        # è¯»å–å›¾åƒ
        image = cv2.imread(image_path)
        if image is None:
            raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {image_path}")
        
        # è½¬æ¢ä¸ºRGB
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # æ£€æµ‹é¢éƒ¨
        faces = self.detector(image)
        if len(faces) == 0:
            raise ValueError("æœªæ£€æµ‹åˆ°é¢éƒ¨")
        
        # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ£€æµ‹åˆ°çš„é¢éƒ¨
        face = faces[0]
        landmarks_object = self.predictor(image, face)
        
        # è¿›è¡Œæƒ…æ„Ÿåˆ†æ
        dict_emotions = self.emotion_estimator.get_emotions(landmarks_object)
        
        result = {
            'arousal': float(dict_emotions['emotions']['arousal']),
            'valence': float(dict_emotions['emotions']['valence']),
            'intensity': float(dict_emotions['emotions']['intensity']),
            'emotion_name': dict_emotions['emotions']['name'],
            'landmarks_raw': [[float(p.x), float(p.y)] for p in landmarks_object.parts()],
            'landmarks_frontal': [[float(p[0]), float(p[1])] for p in dict_emotions['landmarks']['frontal']]
        }
        
        return result
    
    def test_random_features(self, features_file="test_features.txt"):
        """æµ‹è¯•éšæœºç‰¹å¾å‘é‡"""
        print(f"æµ‹è¯•éšæœºç‰¹å¾å‘é‡: {features_file}")
        
        if not os.path.exists(features_file):
            raise FileNotFoundError(f"ç‰¹å¾æ–‡ä»¶ä¸å­˜åœ¨: {features_file}")
        
        # è¯»å–ç‰¹å¾
        features = []
        with open(features_file, 'r') as f:
            for line in f:
                feature_row = [float(x) for x in line.strip().split(',')]
                features.append(feature_row)
        
        print(f"è¯»å–åˆ° {len(features)} ä¸ªç‰¹å¾å‘é‡")
        
        # ä½¿ç”¨sklearnæ¨¡å‹é¢„æµ‹
        predictions = []
        for feature in features:
            feature_array = np.array(feature).reshape(1, -1)
            pred = self.sklearn_model.predict(feature_array)
            predictions.append(pred[0].tolist())
        
        return predictions
    
    def generate_synthetic_test_data(self, num_samples=10):
        """ç”Ÿæˆåˆæˆæµ‹è¯•æ•°æ®"""
        print(f"ç”Ÿæˆ {num_samples} ä¸ªåˆæˆæµ‹è¯•æ ·æœ¬...")
        
        # ç”Ÿæˆéšæœºç‰¹å¾ï¼ˆåŸºäºè®­ç»ƒæ•°æ®çš„ç»Ÿè®¡ç‰¹æ€§ï¼‰
        np.random.seed(42)  # ç¡®ä¿å¯é‡ç°
        
        # å‡è®¾ç‰¹å¾ç»´åº¦ä¸º1275ï¼ˆä¸åŒ…å«ä¸‹é¢šçº¿çš„ç‰¹å¾ï¼‰
        feature_dim = 1275
        
        # ç”Ÿæˆéšæœºç‰¹å¾
        features = np.random.randn(num_samples, feature_dim).astype(np.float32)
        
        # ä½¿ç”¨æ¨¡å‹é¢„æµ‹
        predictions = []
        for i in range(num_samples):
            pred = self.sklearn_model.predict(features[i:i+1])
            predictions.append(pred[0].tolist())
        
        # ä¿å­˜æµ‹è¯•æ•°æ®
        np.savetxt("synthetic_features.txt", features, delimiter=',', fmt='%.6f')
        
        # ä¿å­˜Pythoné¢„æµ‹ç»“æœ
        with open("python_synthetic_predictions.txt", 'w') as f:
            for pred in predictions:
                f.write(','.join([f'{x:.6f}' for x in pred]) + '\n')
        
        print("âœ… åˆæˆæµ‹è¯•æ•°æ®ç”Ÿæˆå®Œæˆ")
        return features, predictions
    
    def save_results(self, results, output_file):
        """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶"""
        if output_file.endswith('.json'):
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
        else:
            # ä¿å­˜ä¸ºCSVæ ¼å¼
            with open(output_file, 'w') as f:
                for result in results:
                    if isinstance(result, dict):
                        f.write(f"{result['arousal']:.6f},{result['valence']:.6f}\n")
                    else:
                        f.write(','.join([f'{x:.6f}' for x in result]) + '\n')
        
        print(f"ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

def main():
    """ä¸»å‡½æ•°"""
    print("========================================")
    print("   Pythonå‚è€ƒç»“æœç”Ÿæˆå™¨")
    print("========================================")
    
    if len(sys.argv) < 2:
        print("ç”¨æ³•:")
        print("  python generate_reference.py image <image_path1> [image_path2] ...")
        print("  python generate_reference.py random <features_file>")
        print("  python generate_reference.py synthetic [num_samples]")
        return
    
    mode = sys.argv[1]
    
    try:
        generator = PythonReferenceGenerator()
        generator.load_models()
        
        if mode == "image":
            # å›¾åƒåˆ†ææ¨¡å¼
            if len(sys.argv) < 3:
                print("é”™è¯¯: å›¾åƒæ¨¡å¼éœ€è¦æŒ‡å®šè‡³å°‘ä¸€ä¸ªå›¾åƒæ–‡ä»¶")
                return
            
            image_paths = sys.argv[2:]
            results = []
            
            for image_path in image_paths:
                try:
                    result = generator.analyze_image(image_path)
                    results.append(result)
                    print(f"âœ… {image_path}: arousal={result['arousal']:.6f}, valence={result['valence']:.6f}")
                except Exception as e:
                    print(f"âŒ {image_path}: {str(e)}")
                    results.append({'arousal': 0.0, 'valence': 0.0, 'error': str(e)})
            
            # ä¿å­˜ç»“æœ
            generator.save_results(results, "python_image_results.json")
            
            # ä¹Ÿä¿å­˜ä¸ºC++å¯è¯»çš„æ ¼å¼
            simple_results = [[r['arousal'], r['valence']] for r in results]
            generator.save_results(simple_results, "python_predictions.txt")
            
        elif mode == "random":
            # éšæœºç‰¹å¾æµ‹è¯•æ¨¡å¼
            features_file = sys.argv[2] if len(sys.argv) > 2 else "test_features.txt"
            predictions = generator.test_random_features(features_file)
            generator.save_results(predictions, "python_random_predictions.txt")
            
        elif mode == "synthetic":
            # åˆæˆæ•°æ®æ¨¡å¼
            num_samples = int(sys.argv[2]) if len(sys.argv) > 2 else 10
            features, predictions = generator.generate_synthetic_test_data(num_samples)
            
        else:
            print(f"æœªçŸ¥æ¨¡å¼: {mode}")
            return
        
        print("\nğŸ‰ Pythonå‚è€ƒç»“æœç”Ÿæˆå®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ æ‰§è¡Œå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
